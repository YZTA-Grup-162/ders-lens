<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AttentionPulse - PyTorch Model Demo</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 30px;
            backdrop-filter: blur(10px);
        }
        h1 {
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        .model-info {
            background: rgba(255, 255, 255, 0.2);
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 30px;
            text-align: center;
        }
        .video-container {
            display: flex;
            justify-content: center;
            margin-bottom: 30px;
        }
        video {
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        }
        .results {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }
        .result-card {
            background: rgba(255, 255, 255, 0.2);
            border-radius: 15px;
            padding: 20px;
            text-align: center;
        }
        .score {
            font-size: 3em;
            font-weight: bold;
            margin: 10px 0;
        }
        .high-score { color: #4CAF50; }
        .medium-score { color: #FF9800; }
        .low-score { color: #F44336; }
        .controls {
            text-align: center;
            margin: 30px 0;
        }
        button {
            background: linear-gradient(45deg, #4CAF50, #45a049);
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 1.1em;
            border-radius: 25px;
            cursor: pointer;
            margin: 0 10px;
            transition: all 0.3s ease;
        }
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }
        button:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }
        .status {
            text-align: center;
            margin: 20px 0;
            font-size: 1.2em;
        }
        .badge {
            display: inline-block;
            background: rgba(255, 255, 255, 0.2);
            padding: 5px 15px;
            border-radius: 20px;
            margin: 0 5px;
            font-size: 0.9em;
        }
        .pytorch-badge {
            background: linear-gradient(45deg, #ee7752, #e73c7e);
        }
        .accuracy-badge {
            background: linear-gradient(45deg, #23a6d5, #23d5ab);
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸ§  AttentionPulse - PyTorch Model Demo</h1>
        <div class="model-info">
            <h2>ðŸŽ¯ 90%+ Accuracy AI Model</h2>
            <p>Trained on FER2013 dataset with 90.17% validation accuracy</p>
            <span class="badge pytorch-badge">PyTorch</span>
            <span class="badge accuracy-badge">90%+ Accuracy</span>
            <span class="badge">Real-time Detection</span>
        </div>
        <div class="video-container">
            <video id="video" width="640" height="480" autoplay></video>
        </div>
        <div class="controls">
            <button id="startBtn" onclick="startCamera()">Start Camera</button>
            <button id="stopBtn" onclick="stopCamera()" disabled>Stop Camera</button>
            <button id="analyzeBtn" onclick="analyzeFrame()" disabled>Analyze Frame</button>
        </div>
        <div class="status" id="status">Click "Start Camera" to begin</div>
        <div class="results" id="results" style="display: none;">
            <div class="result-card">
                <h3>ðŸŽ¯ Attention Score</h3>
                <div class="score" id="attentionScore">--</div>
                <div id="attentionLevel">Unknown</div>
            </div>
            <div class="result-card">
                <h3>ðŸŽ­ Primary Emotion</h3>
                <div class="score" id="primaryEmotion">--</div>
                <div id="emotionConfidence">0%</div>
            </div>
            <div class="result-card">
                <h3>âš¡ Processing Time</h3>
                <div class="score" id="processingTime">--</div>
                <div>milliseconds</div>
            </div>
            <div class="result-card">
                <h3>ðŸ¤– Model Info</h3>
                <div id="modelType">PyTorch Model</div>
                <div id="modelAccuracy">90%+ Accuracy</div>
            </div>
        </div>
    </div>
    <script>
        let video = document.getElementById('video');
        let stream = null;
        let analyzing = false;
        async function startCamera() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                document.getElementById('analyzeBtn').disabled = false;
                document.getElementById('status').textContent = 'Camera started - Ready to analyze!';
            } catch (err) {
                console.error('Error accessing camera:', err);
                document.getElementById('status').textContent = 'Error: Could not access camera';
            }
        }
        function stopCamera() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                video.srcObject = null;
                stream = null;
            }
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            document.getElementById('analyzeBtn').disabled = true;
            document.getElementById('status').textContent = 'Camera stopped';
            document.getElementById('results').style.display = 'none';
        }
        async function analyzeFrame() {
            if (analyzing) return;
            analyzing = true;
            document.getElementById('analyzeBtn').disabled = true;
            document.getElementById('status').textContent = 'Analyzing with PyTorch model...';
            try {
                // Capture frame from video
                const canvas = document.createElement('canvas');
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(video, 0, 0);
                // Convert to base64
                const frameData = canvas.toDataURL('image/jpeg', 0.8);
                // Send to PyTorch API
                const response = await fetch('/api/analyze-frame-pytorch', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        frame_data: frameData,
                        student_id: 'demo-user',
                        timestamp: Date.now()
                    })
                });
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                const result = await response.json();
                displayResults(result);
            } catch (error) {
                console.error('Analysis failed:', error);
                document.getElementById('status').textContent = `Analysis failed: ${error.message}`;
            } finally {
                analyzing = false;
                document.getElementById('analyzeBtn').disabled = false;
            }
        }
        function displayResults(result) {
            document.getElementById('results').style.display = 'grid';
            // Attention score
            const score = result.attention_score || 0;
            document.getElementById('attentionScore').textContent = Math.round(score) + '%';
            document.getElementById('attentionLevel').textContent = result.attention_level || 'Unknown';
            // Color coding
            const scoreElement = document.getElementById('attentionScore');
            if (score >= 70) {
                scoreElement.className = 'score high-score';
            } else if (score >= 40) {
                scoreElement.className = 'score medium-score';
            } else {
                scoreElement.className = 'score low-score';
            }
            // Primary emotion
            const emotions = result.emotions || {};
            document.getElementById('primaryEmotion').textContent = emotions.primary_emotion || 'neutral';
            document.getElementById('emotionConfidence').textContent = Math.round((result.confidence || 0) * 100) + '%';
            // Processing time
            document.getElementById('processingTime').textContent = result.processing_time_ms || 0;
            // Model info
            document.getElementById('modelType').textContent = result.model_type || 'PyTorch Model';
            document.getElementById('modelAccuracy').textContent = result.model_accuracy || '90%+';
            // Update status
            document.getElementById('status').textContent = `Analysis complete! Attention: ${Math.round(score)}%`;
        }
        // Auto-analyze every 2 seconds when camera is running
        setInterval(() => {
            if (stream && !analyzing && !document.getElementById('analyzeBtn').disabled) {
                analyzeFrame();
            }
        }, 2000);
    </script>
</body>
</html>